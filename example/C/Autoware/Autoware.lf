// A lingua franca program with Autoware's general graph structure and constraints
// The tentative constraints are:
// - Sensors: Camera(phase=3, period=33) and LIDAR(phase=10, period=10)
// - LET=30ms or alternatively, the relative deadline is 30
// - Sensor Fusion causes merge (choke) points that collapse multiple logical timelines into one.

target C {
	threads: 2,
	keepalive: false
};

// Send a periodic image out
reactor Camera(offset:time(0), period:time(1 sec)) {
    output image:string;
	timer t(offset, period);

    reaction(t) -> image {=
        SET(image, "kitty");
    =}
}

// Send a periodic LIDAR pointcloud out
reactor LIDAR(offset:time(0), period:time(1 sec)) {
    output pointcloud:string;
    timer t(offset, period);

    reaction(t) -> pointcloud {=
        SET(pointcloud, "INTERSECTION");
    =}
}

// Simulate object detection on GPU
reactor ImageObjectDetection {
    input image:string;
    output object:string;

    
	state thread_id:pthread_t(0);
    
    preamble {=
    #include <pthread.h>
   
    void camera_callback(void* a) {
        // cudaDeviceSynchronize() and copy back goes here.
        schedule(a, 0);
    }
    // Simulate time passing before a callback occurs instead of executing on GPU.
    void* camera_take_time(void* a) {
        struct timespec sleep_time = {(time_t) 0, (long)5000000}; // WCET for GPU is 5msec
        struct timespec remaining_time;
        nanosleep(&sleep_time, &remaining_time);
        camera_callback(a);
        return NULL;
    }
    pthread_t threadId;
	=}

    logical action CUDA(40 msec);
    reaction(image) -> CUDA {=
        // cudaMalloc(&y_state_d, SIZE);
        // cudaMemcpy(&y_state_d, y_state, SIZE, cudaMemcpyHosttoDevice);
        // kernel<<<1,1>>>(y_state_d);

        /* Busy wait for 2 msecs for now instead of calling CUDA kernels */
        interval_t sleep_time = MSEC(2);
        instant_t start_time = get_physical_time();
        while (get_physical_time() < start_time + sleep_time) {};

        pthread_create(&self->thread_id, NULL, &camera_take_time, CUDA);
    =}

    reaction(CUDA) -> object {=
        // cudaMalloc(&y_out_d, SIZE);
        
        // cudaMemcpy(&y_out, results_d, SIZE, cudaMemcpyDevicetoHost);

        // cudaDeviceSynchronize();



        SET(object, "DUMMY Results");
    =}
}

// Simulate LIDAR object detection on GPU
reactor LIDARObjectDetection {
    input pointcloud:string;
    output object:string;

       
	state thread_id:pthread_t(0);
    
    preamble {=
    #include <pthread.h>
   
    void LIDAR_callback(void* a) {
        // cudaDeviceSynchronize() and copy back goes here.
        schedule(a, 0);
    }
    // Simulate time passing before a callback occurs instead of executing on GPU.
    void* LIDAR_take_time(void* a) {
        struct timespec sleep_time = {(time_t) 0, (long)12000000}; // WCET for LIDAR GPU is 12 msec
        struct timespec remaining_time;
        nanosleep(&sleep_time, &remaining_time);
        LIDAR_callback(a);
        return NULL;
    }
    pthread_t threadId;
	=}

    logical action CUDA(100 msec, 20 msec);
    reaction(pointcloud) -> CUDA {=
        // self->y_state = y_in;
        // cudaMalloc(&y_state_d, SIZE);
        // cudaMemcpy(&y_state_d, y_state, SIZE, cudaMemcpyHosttoDevice);
        // kernel<<<1,1>>>(y_state_d);
	//printf("LIDAR triggered at %llu\n", get_physical_time());

        /* Busy wait for 2 msecs for now instead of calling CUDA kernels */
        interval_t sleep_time = MSEC(2);
        instant_t start_time = get_physical_time();
        while (get_physical_time() < start_time + sleep_time) {};

        pthread_create(&self->thread_id, NULL, &LIDAR_take_time, CUDA);        
    =}

    reaction(CUDA) -> object {=
        // cudaMalloc(&y_out_d, SIZE);
	//printf("LIDAR triggered at %llu\n", get_physical_time());
	// printf("LIDAR triggered at %llu\n", get_logical_time());
        
        // cudaMemcpy(&y_out, results_d, SIZE, cudaMemcpyDevicetoHost);

        // cudaDeviceSynchronize();

        SET(object, "Hey look there is a kitty!");
    =}
}


// Fuse LIDAR and Camera detected objects
reactor DataFusion(threshold:time(20 msec)) {
    input imageobject:string;
    input LIDARobject:string;
    output object:string;
    logical action both_ports_are_present(0);

    state tmpImageobject:string("");
    state tmpImageobjectTag:time(0);
    state tmpLIDARobject:string("");
    state tmpLIDARobjectTag:time(0);


    // Handle two ports
    reaction(imageobject, LIDARobject) -> both_ports_are_present {=
        if(imageobject->is_present)
        {
		    self->tmpImageobject = imageobject->value;
		    self->tmpImageobjectTag = get_logical_time(); // Store the tag
		   
		    instant_t window = self->tmpLIDARobjectTag - get_logical_time();
	
		    if(LIDARobject->is_present)
		    {
			schedule(both_ports_are_present, 0);
		    }
	            
	 	    else if(window < (long)1000000)
		    {
		    	schedule(both_ports_are_present, 0);
		    }
		    else
		    {	
		    	// instant_t elapsed = get_physical_time() - get_logical_time(); // How much time has passed - soft
		    	instant_t elapsed = self->threshold; // How much time has passed - hard
	            instant_t remaining = (long)30000000 - elapsed; // How much time is left
	            instant_t schedule_in = remaining - (long)8000000; // Combined WCET of the remaining reactions is 8 msec
		        schedule(both_ports_are_present, schedule_in);
            }
	    // printf("Received image object at %llu physical and %llu logical.\n", get_physical_time(), get_logical_time());
        }
        else if(LIDARobject->is_present)
        {
            self->tmpLIDARobject = LIDARobject->value;
	    	self->tmpLIDARobjectTag = get_logical_time(); // Store the tag
            
	    	instant_t window = self->tmpImageobjectTag - get_logical_time();                                                                                                                                                                       
            
		    if( window < (long)1000000)
	        {
	        	schedule(both_ports_are_present, 0);
	        }
	        else
	        {
			// instant_t elapsed = get_physical_time() - get_logical_time(); // How much time has passed - soft
		    	instant_t elapsed = self->threshold; // How much time has passed - hard
	            instant_t remaining = (long)30000000 - elapsed; // How much time is left    
		        instant_t schedule_in = remaining - (long)8000000; // Combined WCET of the remaining reactions is 8 msec
	            schedule(both_ports_are_present, schedule_in);
	        }	   
	    // printf("Received LIDAR object at %llu physical and %llu logical.\n", get_physical_time(), get_logical_time());
        }


    
    =} deadline(threshold) {=
        printf("Deadline violation detected.\n");
    =}

    // Fuse
    reaction(both_ports_are_present) -> object
    {=

        printf("Fusion scheduled at: ( %llu , %llu ).\n", get_physical_time(), get_logical_time());
       //printf("Fusion: %llu\n", get_physical_time());
        /* Busy wait for 2 msecs for now instead of calling CUDA kernels */
        interval_t sleep_time = MSEC(2);
        instant_t start_time = get_physical_time();
        while (get_physical_time() < start_time + sleep_time) {};
        SET(object, "fused");
    =}
}

// Make driving semantic decisions
reactor Semantics {
    input fusedObject:string;
    output actuation:int;

    reaction(fusedObject) -> actuation {=
        struct timespec sleep_time = {(time_t) 0, (long)6000000};
        struct timespec remaining_time;
        nanosleep(&sleep_time, &remaining_time);
	SET(actuation, 5);
    =}
}

reactor Actuator(threshold:time(33 msec)){
    input actuation:int;

    reaction(actuation) {=
        // Do nothing;
        printf("Actuator scheduled at: ( %llu , %llu ).\n", get_physical_time(), get_logical_time());
       // printf("Actuator: %llu\n", get_physical_time());
    =} deadline(threshold) {=
        printf("Deadline violation detected in Actuator.\n");
    =}
}

/* An alternative path exists between the LIDAR and the actuator for the safety break system */
reactor SafetyBreak {
    input LIDARPointCloud:string;
    output actuation:int;

    reaction(LIDARPointCloud) -> actuation {=
        SET(actuation, 5);
    =}
}


// End-to-end daedline should be 33ms
// LET must be enforced with an output period of 33ms
// GPU is used
// Sub-deadlines (i.e., reaction deadlines) must not be violated

main reactor Autoware {
    c = new Camera(offset = 3 msec, period = 33 msec); // Camera has a phase (startup time) of 3 msec and a period of 33 msec
    l = new LIDAR(offset = 10 msec, period = 10 msec); // Lidar has a phase (spooling up time) of 10 msec and a period of 10 msec
    
    iobjectdetection = new ImageObjectDetection();
    c.image -> iobjectdetection.image;

    lobjectdetection = new LIDARObjectDetection();
    l.pointcloud -> lobjectdetection.pointcloud;

    // Choke point
    fuse = new DataFusion();
    iobjectdetection.object -> fuse.imageobject;
    lobjectdetection.object -> fuse.LIDARobject;


    sem = new Semantics();
    fuse.object -> sem.fusedObject;

    ac = new Actuator();
    sem.actuation -> ac.actuation;

    // An alternative path that activates the safety break system based on LIDAR input
    sb = new SafetyBreak();
    l.pointcloud -> sb.LIDARPointCloud;
    // sb.actuation -> ac.actuation; // Cannot construct the alternative path because actuation may only be connected to a single upstream port

}
